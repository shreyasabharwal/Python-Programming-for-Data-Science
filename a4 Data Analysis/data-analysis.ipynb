{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a4 - Data Analysis\n",
    "Fill in the below code cells as specified. Note that cells may utilize variables and functions defined in previous cells; we should be able to use the `Kernal > Restart & Clear All` menu item followed by `Cell > Run All` to execute your entire notebook and see the correct output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1. Numbers\n",
    "For this part of the assignment, you will analyze some numeric data (counts of library holdings) to investiate how the distribution of numbers in natural data sets obeys the counter-intuitive [Benford's Law](https://plus.maths.org/content/os/issue9/features/benford/index). \n",
    "\n",
    "<small>(This exercise was adapted from Steve Wolfman).</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`holdings_data`** which is a **list** of the contents of the **`data/libraryholdings.txt`** file included in the repository (each line in the file should be a single element in the list). You will need to open up the file and read its contents into a list. You should specify a _local path_ to the file (from this notebook's location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "holdings_data = []\n",
    "with open('data/libraryholdings.txt') as file:\n",
    "    for line in file:\n",
    "        holdings_data.append(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first **ten** items from the `holdings_data` list, each on its own line. (Note that there may be extra line breaks that are included in the data items themselves)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(* Library holdings (# of books in each library), *)\n",
      "\n",
      "(* collected by Christian Ayotte.                 *)\n",
      "\n",
      "(* Labels not available.                          *)\n",
      "\n",
      "\n",
      "\n",
      "12201\n",
      "\n",
      "600778\n",
      "\n",
      "14926\n",
      "\n",
      "37863\n",
      "\n",
      "14866\n",
      "\n",
      "9896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print first ten lines of the file libraryholdings.txt\n",
    "print(*holdings_data[0:10], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the **slice operator (`:`)** to remove the \"heading\" and blank elements from the beginning of the data list, leaving only the list of numbers. The remaining values should continue to be stored (re-stored) in the `holdings_data` variable. Output the new first element in `holdings_data` to demonstrate that it is the first number in the data set.\n",
    "- The values in the list _should_ be strings rather than an integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12201\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# retain only elements that have numbers\n",
    "holdings_data = holdings_data[4:]\n",
    "\n",
    "# display first element of the modified variable, holdings_data\n",
    "print(holdings_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9138\n"
     ]
    }
   ],
   "source": [
    "print(len(holdings_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`lead_digit_counts`** that is a dictionary whose keys are _strings_ of each digit (`\"0\"`, `\"1\"`, `\"2\"`, etc.), and whose values are all the number `0`. You can do this directly or with a loop. Print out the variable after you create it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 0, '2': 0, '3': 0, '4': 0, '5': 0, '6': 0, '7': 0, '8': 0, '9': 0}\n"
     ]
    }
   ],
   "source": [
    "# define dictionary lead_digits_counts \n",
    "lead_digits_counts = {}\n",
    "for i in range(10):\n",
    "    lead_digits_counts[str(i)]=0\n",
    "print(lead_digits_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the number of times each digit appears as the _first digit_ in a value of the `holdings_data` list, storing those counts in the `lead_digit_counts` dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0': 0, '1': 3056, '2': 1606, '3': 1018, '4': 801, '5': 640, '6': 560, '7': 502, '8': 503, '9': 452}\n"
     ]
    }
   ],
   "source": [
    "# count occurence of each digit as first digit in holdings_data list\n",
    "for key, value in lead_digits_counts.items():\n",
    "    count = 0\n",
    "    for list_val in holdings_data:\n",
    "        if (key == list_val[0]):\n",
    "            count = count + 1\n",
    "    lead_digits_counts[key] = count\n",
    "print (lead_digits_counts)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a loop to print out each count in `lead_digit_counts` with the format:\n",
    "```\n",
    "X values have a leading digit of digit Y\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 values have a leading digit of digit 0\n",
      "3056 values have a leading digit of digit 1\n",
      "1606 values have a leading digit of digit 2\n",
      "1018 values have a leading digit of digit 3\n",
      "801 values have a leading digit of digit 4\n",
      "640 values have a leading digit of digit 5\n",
      "560 values have a leading digit of digit 6\n",
      "502 values have a leading digit of digit 7\n",
      "503 values have a leading digit of digit 8\n",
      "452 values have a leading digit of digit 9\n"
     ]
    }
   ],
   "source": [
    "# print the counts of digits in the dictionary\n",
    "for key, value in lead_digits_counts.items():\n",
    "    print(str(value)+\" values have a leading digit of digit \"+key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the _percentage_ of values in the the library holdings data set that have a leading digit **`1`** (round to 2 decimal places). Is this value as predicted by Benford's law?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.44\n",
      "30.1\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# percentage of values in library holdings dataset that have a leading digit 1\n",
    "perc = round((lead_digits_counts[\"1\"]/sum(lead_digits_counts.values())) * 100, 2)\n",
    "print (perc)\n",
    "\n",
    "# calculate using Benford's Law\n",
    "benford_perc = round(math.log10(1+1) * 100, 2)\n",
    "print(benford_perc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Approximately equal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Extra credit challenge:*** Create a single variable `digit_position_counts` that contains the number of times that each digit 0 through 9 appears in _each_ position in the data set. E.g., a `1` appears in the 1st position 3056 times and in the second position 1005 times; a `2` appears in the 1st position 1606 times and in the second position 1044 times.\n",
    "\n",
    "Use this variable to print a \"table\" of the percentage of the time each position contains each digit (e.g., the 1st digit is a `1` 33.44% of the time, a `2` 17.57% of the time, etc).\n",
    "\n",
    "Note that for this extra challenge it is up to you to determine an appropriate data structure (e.g., how to combine dictionaries and lists and tuples) for representing this table. Be sure and include comments explaining your work.\n",
    "\n",
    "Only attempt this problem once you have completed everything else!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pos 1  Pos 2  Pos 3  Pos 4  Pos 5  Pos 6  Pos 7  Pos 8  Pos 9\n",
      "Digit 0      0   1162   1150   1299   1052    161     10      0      0\n",
      "Digit 1   3056   1005    890    837    660    140     14      0      0\n",
      "Digit 2   1606   1044    890    885    713    140      8      0      0\n",
      "Digit 3   1018    971    901    844    687    153      7      0      0\n",
      "Digit 4    801    879    866    885    720    137      5      0      0\n",
      "Digit 5    640    889    930    910    820    150      8      0      0\n",
      "Digit 6    560    859    917    782    761    126     15      0      0\n",
      "Digit 7    502    795    868    927    738    166      9      0      0\n",
      "Digit 8    503    762    903    846    719    144     11      0      0\n",
      "Digit 9    452    772    820    906    742    164      6      1      0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# creating an empty dictionary which is intended to store a set of dictionaries\n",
    "dict_digit_pos = dict()\n",
    "# Looping on each position\n",
    "for position in range(1,10):\n",
    "    dict_digits = {}\n",
    "    # Looping on each digit\n",
    "    for digit in range(10):\n",
    "        digit_position_counts=0\n",
    "        # Looping on each number in the list\n",
    "        for list_val in holdings_data:\n",
    "            if position < len(list_val):\n",
    "                # extracting the digit of number at each position\n",
    "                value = int(list(list_val)[position-1])\n",
    "                # extracting the current number of counts if key exists. If it doesn't exist, initializing count by 0\n",
    "                digit_position_counts = dict_digits.get(\"Digit \"+str(digit),0)\n",
    "                # if the value at 'position' of the number is equal to the digit then increment count by 1 \n",
    "                if (value == digit):\n",
    "                    digit_position_counts += 1\n",
    "            # mapping digit with the number of counts\n",
    "            dict_digits[\"Digit \"+str(digit)] = digit_position_counts\n",
    "    # creating a dictionary of dictionaries - mapping dictionary of digit counts for each position\n",
    "    dict_digit_pos[\"Pos \"+str(position)]=dict_digits    \n",
    "\n",
    "print(pd.DataFrame(dict_digit_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Pos 1  Pos 2  Pos 3  Pos 4  Pos 5  Pos 6  Pos 7  Pos 8  Pos 9\n",
      "Digit 0   0.00  12.72  12.59  14.24  13.82  10.87  10.75    0.0      0\n",
      "Digit 1  33.44  11.00   9.74   9.18   8.67   9.45  15.05    0.0      0\n",
      "Digit 2  17.57  11.42   9.74   9.70   9.37   9.45   8.60    0.0      0\n",
      "Digit 3  11.14  10.63   9.86   9.25   9.03  10.33   7.53    0.0      0\n",
      "Digit 4   8.77   9.62   9.48   9.70   9.46   9.25   5.38    0.0      0\n",
      "Digit 5   7.00   9.73  10.18   9.98  10.77  10.13   8.60    0.0      0\n",
      "Digit 6   6.13   9.40  10.04   8.57  10.00   8.51  16.13    0.0      0\n",
      "Digit 7   5.49   8.70   9.50  10.16   9.70  11.21   9.68    0.0      0\n",
      "Digit 8   5.50   8.34   9.89   9.28   9.45   9.72  11.83    0.0      0\n",
      "Digit 9   4.95   8.45   8.98   9.93   9.75  11.07   6.45  100.0      0\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "# creating a copy of dictionary\n",
    "new_dict=copy.deepcopy(dict_digit_pos)\n",
    "# looping on outer dictionary\n",
    "for position in dict_digit_pos.keys():\n",
    "    # looping on inner dictionaries\n",
    "    for digit in range(10):\n",
    "        # calculating sum of counts of digits at 'position'\n",
    "        sum_position = sum(dict_digit_pos[str(position)].values())\n",
    "        if sum_position!= 0:\n",
    "            # calculating percentage of time each digit appears at the 'position'\n",
    "            new_dict[str(position)][\"Digit \"+str(digit)] = round(dict_digit_pos[str(position)][\"Digit \"+str(digit)]/sum_position * 100, 2)\n",
    "\n",
    "#displaying dictionary of dictonaries using DataFrame\n",
    "print(pd.DataFrame(data = new_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2. Life Expectancy\n",
    "For this part of the assignment, you'll work with data about the life expectancy (in years) for each country in the world in the years 1960 and 2013. Note that this can be really [fun](http://www.ted.com/talks/hans_rosling_shows_the_best_stats_you_ve_ever_seen.html) data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is found in a [.csv](https://en.wikipedia.org/wiki/Comma-separated_values) file: a plain-text data format where each line represents a record (row) of data and where feature (column) is separated by a comma.\n",
    "\n",
    "Read in the contents of the **`data/life_expectancy.csv`** data file, and use it to construct a **list** called **`life_expectancy_list`**. Each element in this list should be a **dictionary** (one for each row in the `csv` file) with the following keys and values:\n",
    "\n",
    "- a key `'country'` whose value is the name of the country (as a string)\n",
    "- a key `'le_1960'` whose value is the life expectancy in 1960 (as a float)\n",
    "- a key `'le_2013'` whose value is the life expectancy in 2013 (as a float)\n",
    "\n",
    "Thus the first record should look like:\n",
    "```\n",
    "{'country': 'Aruba', 'le_1960': 65.56936585, 'le_2013': 75.33217073}\n",
    "```\n",
    "\n",
    "You should use the **`csv`** module to read this file and break up each row into different values. See [the documentation](https://docs.python.org/3/library/csv.html) for an example of how to do this. Print out the _first row_ of your list as a demonstration that you've processed the data correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Aruba', 'le_1960': 65.56936585, 'le_2013': 75.33217073}\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "life_expectancy_list = list()\n",
    "with open('data/life_expectancy.csv', newline='') as file:\n",
    "    reader = csv.reader(file)\n",
    "    next(reader, None)\n",
    "    for row in reader:\n",
    "        temp_dict = {'country':row[0], 'le_1960': float(row[3]), 'le_2013': float(row[4])}\n",
    "        life_expectancy_list.append(temp_dict)\n",
    "print(life_expectancy_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add another item to each dictionary in the `life_expectancy_list` whose **key** is `change` and whose **value** is the change in life expectancy from 1960 to 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Aruba', 'le_1960': 65.56936585, 'le_2013': 75.33217073, 'change': 9.762804880000004}\n"
     ]
    }
   ],
   "source": [
    "# add item to life_expectancy_list\n",
    "for item_list in life_expectancy_list:\n",
    "    item_list[\"change\"] = item_list[\"le_2013\"] - item_list[\"le_1960\"]\n",
    "print(life_expectancy_list[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`num_small_gain`** that stores the **number of countries** whose life expectancy did not improve by 5 years or more between 1960 and 2013. This will include counties whose life expectancy has worsened. Print out this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n"
     ]
    }
   ],
   "source": [
    "num_small_gain = 0\n",
    "\n",
    "# calculate number of countries having life expectancy improvement by less than 5 years\n",
    "for item_list in life_expectancy_list:\n",
    "    num_small_gain+=(item_list['change'] < 5 + 0)\n",
    "print (num_small_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a variable **`most_improved`** that is the **name of the country** with the largest gain in life expectancy (between 1960 and 2013). Print out this variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maldives 42.07575609\n"
     ]
    }
   ],
   "source": [
    "max_val = -1 * math.inf\n",
    "for item_list in life_expectancy_list:\n",
    "    if(item_list['change'] > max_val):\n",
    "        max_val = item_list['change'] \n",
    "        most_improved = item_list['country']\n",
    "print (most_improved, max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`compare_country_le()`** that takes in the names of _two_ countries, and returns a **tuple** containing the following information:\n",
    "- the name of the country with the greater life expectancy,\n",
    "- the life expectancy in 2013 of that country\n",
    "- the difference between the life expectancies in 2013\n",
    "\n",
    "Use your function to print the comparison between the life expectancies of the _United States_ and _Cuba_.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Cuba', 79.23926829, 0.39780487999999536)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_country_le(country_1, country_2):\n",
    "    \"\"\" \n",
    "    compare life expectancies of two countries\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    country_1: str, name of country\n",
    "    country_2: str, name of country\n",
    "    Returns:\n",
    "    ---------\n",
    "    name of country with greater life expectancy\n",
    "    life expectancy in 2013 of that country\n",
    "    difference between life expectancies in 2013\n",
    "    \"\"\"\n",
    "    temp=list()\n",
    "    for list_item in life_expectancy_list:\n",
    "        if (list_item['country'] == country_1):\n",
    "            l_1 = list_item\n",
    "        elif (list_item['country'] == country_2):\n",
    "            l_2 = list_item\n",
    "    if (l_1['le_2013'] > l_2['le_2013']):\n",
    "        return (l_1['country'], l_1['le_2013'], l_1['le_2013'] - l_2['le_2013'])\n",
    "    else:\n",
    "        return (l_2['country'], l_2['le_2013'], l_2['le_2013'] - l_1['le_2013'])\n",
    "    \n",
    "compare_country_le('United States', 'Cuba')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3. Readability\n",
    "For this part of the assignment, you will calculate the [readability](https://en.wikipedia.org/wiki/Readability) of a text document using the [Dale-Chall Readability Formula](http://www.readabilityformulas.com/new-dale-chall-readability-formula.php). This method determines how \"easy\" it is to read a particular (English) document by considering the length of sentences and how many of the words used are \"easy\" to understand (based on a pre-defined list of \"easy\" words)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting real-world text documents into words and sentences is non-trivial (English is hard!). To make this easier, you should use the [Natural Language Toolkit (nltk)](http://www.nltk.org/index.html) module. This module is included with Anacaonda, but does require some additional data source files to be installed on your computer. You _should_ be able to do this by running the below cell (you only need to run it once)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to C:\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import download\n",
    "download('punkt')\n",
    "download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will also need to load the list of \"easy\" words into memory. This list can be found in the **`data/dale-chall.txt`** file. Open this file and read its entire contents into a **list** variable (e.g., `easy_words_list`), where each element in the list is a single line (word) in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easy_words_list=list()\n",
    "# create a list of easy words\n",
    "with open('data/dale-chall.txt') as file:\n",
    "    for line in file:\n",
    "        easy_words_list.append(line.strip().lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to \"look up\" easy words, convert the easy words list into a **dictionary** (e.g., `easy_words_dict`), where each **key** is a word, and each **value** is `True` (that the word is in the list).\n",
    "- Make sure you do not include newline characters in your keys!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "easy_words_dict={}\n",
    "# create a dictionary with each key as an easy word and value as True\n",
    "for item in easy_words_list:\n",
    "    easy_words_dict[item.lower()] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, define a dictionary **`readability_grade_dict`** to use for looking up the \"grade level\" associated with a readability score (see [this table](https://en.wikipedia.org/wiki/Dale%E2%80%93Chall_readability_formula#Formula)). This dictionary should have **keys** that are ___tuples___ giving the range of score for a particular grade (e.g., `(5.0, 5.9)`), and **values** that are ___strings___ representing the grade (e.g., `\"5th or 6th grade\"`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define dictionary for grade levels\n",
    "readability_grade_dict = {\n",
    "    (0, 4.9): '4th grade or lower',\n",
    "    (5, 5.9): '5th or 6th grade',\n",
    "    (6, 6.9): '6th or 7th grade',\n",
    "    (7, 7.9): '7th or 8th grade',\n",
    "    (8, 8.9): '8th or 9th grade',\n",
    "    (9, 9.9): '9th or 10th grade'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`print_grade()`** that takes in a readability score (a number greater than or equal to 0), and **prints** a string representing the grade associated with that score (from your `readability_grade_dict` dictionary).\n",
    "- _Hint:_ loop through the items in the dictionary and determine which \"tuple\" key has elements that the score falls between. Be sure and round to the nearest decimal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_grade(score):\n",
    "    \"\"\" \n",
    "    print grade associated with the score\n",
    "    Parameters:\n",
    "    -----------\n",
    "    score: float; readability grade score\n",
    "    Returns:\n",
    "    ---------\n",
    "    value: str; grade\n",
    "    \"\"\"\n",
    "    for key, value in readability_grade_dict.items():\n",
    "        if (key[0] <= score <= key[1]):\n",
    "            print (value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to calculate the readability scores! Define a function **`count_sentences()`** that counts the number of sentences in a string. Use the [sent_tokenize()](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.sent_tokenize) function from the `nltk.tokenize` module to break up a string into sentences (this is like the string `split()` function, but it splits into sentences rather than dividing by spaces).\n",
    "- For help and an example, see [this guide](http://textminingonline.com/dive-into-nltk-part-ii-sentence-tokenize-and-word-tokenize).\n",
    "- You do not need to do any extra processing beyond that provided by the `sent_tokenize()` function.\n",
    "- Test your function on a simple pair or trio of sentences!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def count_sentences(str_of_sentences):\n",
    "    \"\"\" \n",
    "    return number of sentences in a string\n",
    "    \"\"\"\n",
    "    sentences_list = sent_tokenize(str_of_sentences)\n",
    "    return (len(sentences_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`extract_words()`** that takes in a string and returns a _list_ of all of the words in that string. Use the [word_tokenize()](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.word_tokenize) function from the `nltk.tokenize` module to break up the string into words.\n",
    "- The `nltk` tokenizer includes each punctuation character (e.g., commas, periods) as individual \"words\". Your list should not include these items. You can use a string method to determine whether or not the word starts with a punctuation symbol, and if so exclude it. _Hint_ think about keeping good words, rather than throwing away the bad! Note that you do not need to do any special consideration for contractions or other words that include their own punctuation.\n",
    "- Test your function on a simple sentence (with punctuation!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test',\n",
       " 'your',\n",
       " 'function',\n",
       " 'on',\n",
       " 'a',\n",
       " 'simple',\n",
       " 'sentence',\n",
       " 'with',\n",
       " 'punctuation']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "def extract_words(str_of_words):\n",
    "    \"\"\" \n",
    "    return the list of words in the string\n",
    "    \"\"\"\n",
    "    word_list = word_tokenize(str_of_words)\n",
    "    word_list = [word.lower() for word in word_list if word[0].isalpha()]\n",
    "    return word_list\n",
    "\n",
    "extract_words(\"Test your function on a simple sentence (with punctuation!).â€˜\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`count_easy_words()`** that takes in a _list_ of words as an argument and returns the number of words that are \"easy\".\n",
    "\n",
    "- Your function should look up each word in the `easy_words_dict` you defined earlier. _Do not look up words in the list_ (the dictionary is much faster!). Be careful to look up lowercase versions of the word.\n",
    "\n",
    "- Your function should handle detecting different parts of speech (e.g., plurals, different verb conjugations, etc.). You can do this by using the **`WordNetLemmatizer()`** function from the `nltk.stem.wordnet` module&mdash;which produces a \"lemmatizer\" object. You can call the **`lemmatize()`** method on this object to reduce a word to its \"base\" form. See [this example](https://pythonprogramming.net/lemmatizing-nltk-tutorial/). Note that you should reduce words to both their basic noun AND verb forms (you will need to call the function twice: once with `'n'` (noun) and once with `'v'` (verb) as the second argument!)\n",
    "\n",
    "- You can test your function on the word list: `['My','words','spoken','have','consequences']`, which should have 4 of the 5 words considered easy (not \"consequences\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer \n",
    "def count_easy_words(list_words):\n",
    "    \"\"\" \n",
    "    count number of easy words from the list of words\n",
    "    \"\"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    count_easy = 0\n",
    "    for word in list_words:\n",
    "        word_n = lemmatizer.lemmatize(word, 'n')\n",
    "        word_v = lemmatizer.lemmatize(word, 'v')\n",
    "        if (word_n.lower() in easy_words_dict.keys() or word_v.lower() in easy_words_dict.keys()):\n",
    "            count_easy+=1\n",
    "    return count_easy\n",
    "\n",
    "print(count_easy_words(['My','words','spoken','have','consequences']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function **`calc_readability_score()`** that takes in a string of text and returns a readability \"score\" for the test based on the [Dale-Chall readability formula](https://en.wikipedia.org/wiki/Dale%E2%80%93Chall_readability_formula#Formula). Call your previous functions to calculate the number of sentences, total words, and number of difficult (not easy) words.\n",
    "- Don't forget to adjust the score if the text is more than 5% difficult words!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_readability_score(str_text):\n",
    "    \"\"\" \n",
    "    calculate readability score for the test based on Dale-Chall readbility formula\n",
    "    \"\"\"\n",
    "    # number of sentences in str_text\n",
    "    num_sent = count_sentences(str_text)\n",
    "    # list of words in str_text\n",
    "    list_words = extract_words(str_text)\n",
    "    # number of words in str_text\n",
    "    num_words = len(list_words)\n",
    "    # number of difficult words in str_text\n",
    "    num_difficult_words = num_words - count_easy_words(list_words)\n",
    "    perc_diff = (num_difficult_words/num_words) * 100\n",
    "    # Dale-Chall readability formula\n",
    "    score = (0.1579 * perc_diff) + (0.0496 * (num_words/num_sent))\n",
    "    # adjust score if text has more than 5% difficult words\n",
    "    if (perc_diff > 5):\n",
    "        score+=3.6365\n",
    "    print (num_sent, num_words, num_difficult_words)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in the text of the `data/alice.txt` file (the full text of Alice in Wonderland) _as a single string_. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# read file alice.txt\n",
    "with open('data/alice.txt', encoding=\"utf8\") as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the readability score for the `alice.txt` file and print it out. Then print out the reading grade associated with that score. Use your previously-defined functions!\n",
    "- For testing, note that my calculations show `alice.txt` has 977 sentences and 27198 words, of which 3610 are difficult. This leads to a readability score of ~7.113."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "977 27198 3610\n",
      "7.113090902410715\n",
      "7th or 8th grade\n"
     ]
    }
   ],
   "source": [
    "readability_score = calc_readability_score(data)\n",
    "print(readability_score)\n",
    "print_grade(readability_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note that this result may not be an especially accurate model of a text's readability&mdash;after all, it's just based on a simple estimation!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "84px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
